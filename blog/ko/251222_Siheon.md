<img src="img/blog/251222_Siheon/title.png" alt="Overview of FACS-Net architecture" class="img-medium">

이번 글에서는 **Automation in Construction (Elsevier)** 2026년 호에 게재된 제 논문, "**Frequency-aware crack segmentation network (FACS-net) and crack topology loss (CT-loss) for thin cracks**"의 핵심 내용을 소개하려 합니다.

건설 현장의 안전을 진단할 때 가장 중요한 신호 중 하나가 바로 '**균열(Crack)**'입니다. 특히 눈에 잘 띄지 않는 초기 미세 균열을 찾아내는 것이 무엇보다 중요한데, 기존 딥러닝 모델들은 이 부분을 해결하는 데 큰 어려움을 겪고 있었습니다.

저는 이 문제의 원인을 데이터 부족이 아닌 딥러닝의 구조적 특성인 '**주파수 편향(Spectral Bias)**'에서 찾았고, 이를 해결하기 위해 새로운 모델 구조(FACS-Net)와 손실 함수(CT-Loss)를 제안했습니다. 이번 포스팅을 통해 저희가 어떤 방식으로 이 난제를 풀었는지 공유하고자 합니다.

---

<img src="img/blog/251222_Siheon/Fig1.png" alt="Figure 1. Edge Ratio" class="img-medium">

---

## 문제의 시작: 딥러닝이 얇은 균열을 보지 못하는 이유

연구를 진행하며 가장 의아했던 점은, 최신 딥러닝 모델들이 굵고 선명한 균열은 기가 막히게 찾으면서도 **얇은 균열(Thin Cracks)** 앞에서는 속수무책이라는 것이었습니다.

이 현상을 분석해보니 '**Spectral Bias(주파수 편향)**'라는 딥러닝의 고질적인 특성이 원인이었습니다.
* **저주파(Low-frequency):** 이미지의 배경, 전체적인 형태 등 부드럽게 변하는 영역. 딥러닝 모델이 아주 잘 학습합니다.
* **고주파(High-frequency):** 얇은 균열, 경계선(Edge), 텍스처 등 급격하게 변하는 영역. 딥러닝 모델은 학습 과정에서 이 부분을 무시하거나 나중으로 미루는 경향이 있습니다.

특히 균열이 얇아질수록 전체 픽셀 중 **경계선(Edge)** 이 차지하는 비중이 급격히 높아지는데, 기존 모델들은 인코더에서 이미지를 압축(Down-sampling)하는 과정에서 이 중요한 고주파 정보를 잃어버리고 있었습니다. 결국 모델에게 미세 균열은 '중요한 신호'가 아니라 '배경 노이즈'로 취급되고 있었던 것입니다.

---

<img src="img/blog/251222_Siheon/Fig2.png" alt="Figure 2. Overview of the proposed FACS-Net structure" class="img-medium">

---

## 해결책 1: 주파수를 제어하는 모델 (FACS-Net)

"모델이 고주파 성분을 보기 싫어한다면, **강제로 보게 만들자**"는 것이 제 접근이었습니다.
이를 위해 '**FACS-Net(Frequency-Aware Crack Segmentation Network)**'이라는 새로운 아키텍처를 설계했습니다.

기존 인코더-디코더 구조에 '**FPCM(Frequency Preference Control Module)**'을 도입한 것이 핵심입니다. 이 모듈은 다음과 같이 작동합니다:
1.  **주파수 분리:** 이미지를 주파수 도메인(FFT)으로 변환하여 저주파와 고주파 성분으로 나눕니다.
2.  **고주파 강조:** 모델이 놓치기 쉬운 고주파 대역(균열의 디테일)에 가중치를 부여하여, 이 정보가 소실되지 않고 디코더로 전달되게 합니다.
3.  **점진적 복원:** 저해상도에서 고해상도로 이미지를 키워나갈 때(Progressive Growing), 각 단계마다 이 주파수 정보를 주입하여 흐릿한 균열을 선명하게 복원합니다.

---

<img src="img/blog/251222_Siheon/Fig6.png" alt="Figure 6. Visual comparison of crack segmentation across varying crack widths" class="img-medium">

---

## 해결책 2: 형태를 보존하는 손실 함수 (CT-Loss)

모델이 픽셀을 잘 찾더라도, 균열이 끊겨서(Fragmented) 탐지된다면 현장에서는 무용지물입니다. 안전 진단에서는 균열이 어디서 시작해 어디로 이어지는지 그 **연결성(Topology)** 을 파악하는 것이 핵심이기 때문입니다.

기존의 손실 함수(BCE Loss 등)는 픽셀 하나하나의 정답 여부만 따지기 때문에, 균열이 점선처럼 끊겨도 "대체로 맞았다"고 판단하는 문제가 있었습니다.

이를 해결하기 위해 저는 세 가지 요소를 결합한 **CT-Loss(Crack Topology Loss)** 를 제안했습니다:

<img src="img/blog/251222_Siheon/Eq17.png" alt="Crack Topology Loss" class="img-medium">

1.  **BCE Loss:** 전체적인 픽셀 정확도를 잡습니다.
2.  **SEMEDA:** 균열의 '**경계선(Edge)**'을 선명하게 유지하도록 돕습니다.
3.  **Soft-CTS:** 기존에 미분이 불가능해 학습에 쓸 수 없었던 CTS(Crack Topology Score) 지표를 미분 가능한 형태(**Soft-CTS**)로 변형했습니다. 이를 통해 모델은 "균열이 끊어지면 틀린 것이다"라는 것을 학습하게 됩니다.

---

<img src="img/blog/251222_Siheon/Fig6.png" alt="Figure 6. Visual comparison of crack segmentation across varying crack widths" class="img-medium">

---

## 실험 결과: 미세 균열에서 압도적인 성능 향상

이 아이디어가 실제로 효과가 있었을까요?
대규모 데이터셋인 **CrackVision12K**를 사용하여 실험한 결과, 특히 **2픽셀 이하의 아주 얇은 균열**에서 놀라운 성능 향상을 확인했습니다.

기존 SOTA 모델(Hybrid-Segmentor)과 비교했을 때:
* **IoU (정확도):** 0.160 → **0.466** (약 3배 향상)
* **CTS (연결성 점수):** 0.585 → **0.945** (끊김 없이 매끄럽게 탐지)

다른 모델들이 미세 균열을 노이즈로 인식하거나 점선처럼 끊어서 탐지할 때, FACS-Net은 **끊김 없는 실선**으로 온전하게 찾아내는 것을 확인할 수 있었습니다.

---

## 맺음말

이번 연구는 단순히 모델의 성능을 높이는 것을 넘어, 딥러닝이 구조적으로 취약했던 '**고주파 영역**'과 '**위상학적 연결성**'을 어떻게 학습시킬 것인가에 대한 고민의 결과입니다.

FACS-Net과 CT-Loss를 통해 제안한 방법론이, 앞으로 균열뿐만 아니라 전선, 혈관, 도로망과 같이 **가늘고 연속성이 중요한(Thin & Continuous)** 객체를 다루는 다양한 비전 연구에 도움이 되기를 바랍니다.

---

## 글쓴이 소개

<div class="author-card">
    <img src="img/member/student/주시헌.jpg" alt="주시헌" class="author-photo">
    <div class="author-info">
        <h4>주시헌 (Siheon Joo)</h4>
        <p class="author-affiliation">연세대학교 건설환경공학과 스마트 인프라 연구실(SIL) 통합과정</p>
        <p class="author-bio">
            건설 인프라를 위한 컴퓨터 비전과 AI 모델 아키텍처를 연구하고 있다. 특히 딥러닝이 놓치기 쉬운 고주파 대역의 정보 복원, 초해상도(Super-Resolution), 그리고 미세 균열 분할(Crack Segmentation)과 같이 정밀함이 요구되는 문제 해결에 집중하고 있다. FACS-Net 연구를 통해 얇고 미세한 객체의 구조적 연결성을 보존하는 생성 및 분석 기술로 연구 분야를 확장해 나가고 있다.
        </p>
        <div class="author-contact">
            <a href="mailto:sh.joo@yonsei.ac.kr"><i class="fas fa-envelope"></i> sh.joo@yonsei.ac.kr</a>
            <a href="tel:+82-10-8690-7661"><i class="fas fa-phone"></i> +82-10-8690-7661</a>
            <a href="https://sh-joo.github.io/" target="_blank"><i class="fas fa-globe"></i> sh-joo.github.io</a>
        </div>
    </div>
</div>