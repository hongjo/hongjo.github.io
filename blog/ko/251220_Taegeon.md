<img src="img/blog/251220_Taegeon/title.png" alt="Overview of the proposed LVLM-based construction safety assessment framework" class="img-medium">
이 글은 Automation in Construction (Elsevier)에 2025년 게재된 논문 "Optimizing large vision-language models for context-aware construction safety assessment"를 바탕으로, 생성형 AI와 Large Vision-Language Model(LVLM)을 활용하여 기존 AI 기반 안전 모니터링 시스템의 한계를 어떻게 극복하려 했는지를 리뷰한다.

이 연구는 단순한 객체 검출을 넘어 맥락 인식 기반의 추론이 가능한 건설 현장 안전 평가 접근법을 제시한다는 점에서 주목할 만하다. 기존의 컴퓨터 비전 모델들이 건설 안전 모니터링에 널리 활용되어 왔으나, 이들은 대부분 사전 정의된 클래스 내에서 객체를 검출하는 데 국한되어 있다. 이러한 한계로 인해 공간적 관계와 맥락 정보에 대한 이해가 필요한 복잡한 위험 상황을 평가하기 어렵다.

건설 산업에서 AI 기반 안전 모니터링 시스템은 주로 개인보호구(PPE) 미착용 감지, 작업자-장비 간 근접도 모니터링, 제한 구역 침입 식별 등의 작업에 활용되어 왔다. 그러나 실제 건설 현장의 위험 상황은 단순한 객체 검출만으로는 적절히 대응하기 어려운 복잡한 다단계 인식 과정을 필요로 하는 경우가 많다.

이 글에서는 Large Vision-Language Model을 활용하여 맥락 인식 기반 안전 평가를 수행하는 연구를 리뷰하며, 제안된 접근법이 기존 방법들과 어떻게 다르고 건설 안전 모니터링에서 어떤 실질적 한계를 해결하는지를 살펴본다.

---

## 기존 건설 현장 안전 모니터링 시스템의 한계

딥러닝 기반 안전 모니터링 시스템은 건설 현장 관리에서 상당한 발전을 이루었다. 그러나 이러한 시스템들은 실제 건설 환경에 배치될 때 몇 가지 근본적인 한계에 직면한다.

첫째, 대부분의 컴퓨터 비전 모델은 사전 정의된 클래스 내에서 객체를 검출하는 데 제한된다. 예를 들어, 일반적인 안전 규정에 따르면 지게차가 운반하는 건설 자재는 운전자의 시야선 아래에 위치해야 한다. 이 규정을 준수하는지 확인하려면 모델은 지게차와 자재를 검출할 뿐만 아니라 자재 높이를 운전자의 시야선과 비교해야 한다. 이러한 다단계 인식 과정은 기존 객체 검출 모델의 능력을 넘어선다.

둘째, 다양한 위험 상황에서 이러한 세부적인 인식을 수행할 수 있는 모니터링 시스템을 개발하려면 상당한 시간과 노력이 필요하다. 정확한 모델을 만들기 위해서는 건설 현장에서 마주하는 다양한 객체와 상황을 포함하는 대량의 고품질 학습 데이터를 수집, 라벨링, 전처리해야 한다.

셋째, 조명, 날씨, 객체 가림 등 건설 현장 조건의 변동성과 예측 불가능성에 대응하려면 견고한 성능을 보장하기 위한 엄격한 테스트와 최적화가 필요하다.

---

## Large Vision-Language Model과 그 가능성

Large Vision-Language Model(LVLM)은 이러한 문제들에 대한 유망한 해결책을 제시한다. CLIP, BLIP, PaLI, LLaVA와 같은 모델들은 대규모 이미지-텍스트 쌍으로 사전 학습되어 이미지 캡션 생성과 시각적 질문 응답(VQA) 같은 비전-언어 작업에서 우수한 성능을 보인다.

LVLM은 이미지에서 광범위한 객체를 인식하고 맥락적 관계를 이해하는 능력으로 인해 건설 안전 모니터링에 상당한 잠재력을 제공한다. 분류 결과만 출력하는 기존 컴퓨터 비전 모델과 달리, LVLM은 상황을 자연어로 해석하고 설명할 수 있어 복잡한 시나리오에 대한 추론이 필요한 안전 평가 작업에 특히 적합하다.

그러나 COCO Captions, CC12M, LAION 같은 데이터셋으로 학습된 범용 LVLM은 주로 일반적인 상황으로 구성되어 있어 건설 현장에 특화된 맥락적 세부 정보가 부족하다. 효과적인 LVLM 기반 건설 안전 모니터링 시스템을 개발하려면, 모델이 범용 사전 학습 데이터셋에 적절히 포함되지 않은 건설 환경의 고유한 맥락을 이해해야 한다.

---

## 연구의 핵심 질문

이 논문은 다음 질문에서 출발한다.

> 생성형 AI는 건설 현장 이미지를 단순히 설명하는 수준을 넘어, 해당 상황의 안전 여부를 맥락적으로 판단하고 설명할 수 있을까?

이를 위해 연구진은 도메인 특화 이미지-텍스트 데이터 생성, 객체 인식 향상을 위한 비전 인코더 미세조정, 맥락 인식 안전 추론을 위한 Low-Rank Adaptation(LoRA) 기반 모델 조정을 결합한 프레임워크를 제안한다. 이 접근법은 안전에 민감한 시나리오에서 시각적 이해와 맥락 인식 추론을 모두 향상시키도록 설계되었다.

---

## 전체 방법 개요

제안된 방법은 다음 세 단계로 구성된다.

1. 건설 안전 도메인 특화 instruction-following 데이터 생성
2. 건설 특화 시각 요소 인식 향상을 위한 비전 인코더 미세조정
3. 맥락 인식 안전 평가를 위한 LVLM의 LoRA 미세조정

이 프레임워크는 범용 LVLM을 상세한 설명과 함께 안전 평가를 수행할 수 있는 특화 모델로 전환한다.

---

<!-- 논문 Figure 1 -->
<img src="img/blog/251220_Taegeon/Figure1.jpg" alt="Overview of the proposed LVLM-based construction safety assessment framework" class="img-medium">

---

## Step 1. Instruction-Following 데이터 생성

건설 안전 평가를 위해 LVLM을 학습시키려면 도메인 특화 이미지-텍스트 쌍 데이터셋이 필요하다. 그러나 실제로 이러한 데이터셋은 매우 제한적이다. 이 연구의 원천 데이터는 "The Open AI Dataset Project"(AI-Hub, 대한민국)에서 획득했으며, 건설 현장 이미지, 건설 객체에 대한 폴리곤 마스크, 위험 상황을 설명하는 간단한 캡션, 위험 영역을 강조하는 바운딩 박스를 포함한다.

연구진은 GPT-4V에 두 가지 특정 작업에 맞춘 출력을 생성하도록 지시하는 프롬프트를 설계했다.

- 위험 상황에 대한 상세 설명: 모델은 비계, 기계, 작업자, 안전 장비 등 핵심 요소를 식별하고 설명하는 철저한 분석을 수행하도록 지시받는다. 출력은 단순한 객체 인식을 넘어 포괄적이고 안전 지향적인 설명을 제공한다.

- 안전 문제를 다루는 복잡한 추론 작업: 모델은 제공된 이미지와 바운딩 박스를 기반으로 안전 관련 질문을 생성한 후, 장면 분석을 바탕으로 합리적인 답변을 제공한다. 이를 통해 모델은 안전 조건에 대해 비판적으로 사고하도록 학습된다.

이미지 입력을 직접 포함함으로써 GPT-4V는 상세한 시각 정보를 캡처하여 건설 안전 특화 맥락으로 출력을 풍부하게 한다. 정확하고 안전 중심적인 설명과 추론을 생성하는 데 도움이 되도록 few-shot 예시가 프롬프트에 포함된다.

<img src="img/blog/251220_Taegeon/Figure4.jpg" alt="Overview of the proposed LVLM-based construction safety assessment framework" class="img-medium">

---

## Step 2. 비전 인코더 미세조정

안전 평가의 정확도는 모델이 이미지에서 객체와 그 공간적 배치를 얼마나 정확하게 인식하는가에 크게 의존한다. LVLM의 비전 인코더는 이미지에서 고수준 표현을 추출하지만, 사전 학습된 인코더는 소스 도메인과 타겟 도메인 간의 데이터 분포 차이로 인해 특정 도메인에서 어려움을 겪는 경우가 많다.

이 한계를 해결하기 위해 연구진은 LLaVA 1.5에서 사용되는 CLIP ViT-L-336px 비전 인코더를 이중 입력 접근법으로 미세조정한다. 전체 이미지와 하위 영역(위험 상황을 식별하는 바운딩 박스로 잘린 영역) 모두 이미지 인코더에 입력된다. 이를 통해 모델은 전체 이미지에서 전역 맥락과 잘린 하위 영역에서 지역 세부 정보를 모두 학습할 수 있다.

건설 데이터셋의 상대적으로 작은 규모를 고려하여 과적합을 방지하기 위해 선택적 미세조정 전략이 사용된다. CLIP 모델 비전 인코더의 24개 트랜스포머 레이어 중 상위 레이어(15-24)만 미세조정하고, 나머지 하위 레이어(1-14)는 동결한다. 하위 레이어를 동결하면 에지와 텍스처 같은 일반적인 시각 특징을 추출하는 사전 학습 모델의 능력이 보존되고, 상위 레이어를 미세조정하면 건설 특화 특성에 적응할 수 있다.

<img src="img/blog/251220_Taegeon/Figure5.jpg" alt="Overview of the proposed LVLM-based construction safety assessment framework" class="img-medium">

---

## Step 3. 안전 평가를 위한 LoRA 미세조정

비전 인코더를 정제한 후, 모델은 Low-Rank Adaptation(LoRA)을 사용하여 추가 최적화된다. LoRA는 어텐션 레이어에 학습 가능한 저랭크 행렬을 도입하여 학습 가능한 파라미터 수를 크게 줄이면서 효율적인 파라미터 업데이트를 가능하게 한다. 이를 통해 모델은 전체 재학습 없이 건설 안전 도메인에 적응할 수 있다.

미세조정 전략은 비전 인코더의 15-24 레이어를 프로젝션 레이어 및 대규모 언어 모델과 함께 선택적으로 동결 해제한다. 프로젝션 레이어는 비전 인코더의 출력을 언어 모델과 호환되는 임베딩 공간으로 변환하여 시각적 단서가 텍스트 추론과 효과적으로 정렬되도록 한다. 대규모 언어 모델은 통합된 입력을 처리하여 지시를 해독하고 일관되고 맥락 특화된 응답을 생성한다.

이 접근법을 통해 모델은 다음을 수행할 수 있게 된다:
- 상황을 "안전" 또는 "위험"으로 분류
- 분류를 뒷받침하는 상세한 텍스트 근거 제공
- 특정 위험을 식별하고 왜 안전 위험을 초래하는지 설명

---

<!-- 논문 Figure 6 -->
<img src="img/blog/251220_Taegeon/Figure6.jpg" alt="Overview of the proposed LVLM-based construction safety assessment framework" class="img-medium">

---

## 실험 결과 요약

모델은 사다리 안전, 비계 작업, 이동식 크레인 운전, 신호수 배치, 소화기 배치, 지게차 운전 등 건설 현장에서 흔히 발견되는 10가지 위험 상황을 다루는 400개 이미지로 평가되었다. 각 상황은 안전한 경우와 위험한 경우를 모두 포함했다.

이미지 캡션 작업에서 제안된 모델은 우수한 성능을 보였다:
- 평균 ROUGE-L: 0.3852 (GPT-4V: 0.1898, LLaVA 1.5: 0.2183 대비)
- 평균 SPICE: 0.3615 (GPT-4V: 0.1740, LLaVA 1.5: 0.1364 대비)
- 평균 SBERT 기반 유사도: 0.7484 (GPT-4V: 0.6459, LLaVA 1.5: 0.5872 대비)

안전 평가에서 미세조정된 모델은 안전 상태 예측에서 94.25%의 정확도를 달성하여 GPT-4V(53.25%)와 LLaVA 1.5(48%)를 크게 능가했다. 텍스트 정당화의 품질은 GPT-4V 기반 평가와 전문가 기반 평가 모두에서 평가되었으며, 미세조정된 모델이 일관되게 가장 높은 관련성과 선호도 점수를 받았다.

주목할 만한 발견은 베이스라인 모델들이 종종 안전한 상황을 위험으로 잘못 식별하거나 중요한 안전 요소를 인식하지 못했다는 점이다. 예를 들어, 덤프트럭 작업 중 신호수가 있을 때 GPT-4V와 LLaVA 1.5는 때때로 상황을 위험으로 잘못 분류하여 안전한 작업을 보장하는 신호수의 역할을 인식하지 못했다.

---

<!-- 논문 성능 비교 그래프 -->
<img src="img/blog/251220_Taegeon/Figure11.jpg" alt="Overview of the proposed LVLM-based construction safety assessment framework" class="img-medium">

---

## 연구의 의의와 활용 가능성

이 연구의 가치는 다음과 같이 정리할 수 있다.

- 단순 객체 검출을 넘어 맥락 인식 건설 안전 평가를 위한 LVLM의 가능성 제시
- 건설 도메인에 비전-언어 모델을 적용하는 데 있어 지식 격차 해소
- 데이터 부족을 극복하기 위한 도메인 특화 학습 데이터 생성 프레임워크 제공
- 안전에 민감한 응용을 위해 시각적 이해와 맥락적 추론을 결합하는 방법 제안

제안된 모델은 시각적 검사 워크플로우, 이미지 기반 안전 문서화, 자동화된 안전 보고 시스템에 통합될 수 있다. 안전 상태 분류, 맥락적 설명, 제안된 시정 조치를 제공함으로써 모델은 안전 관리자가 현장 상태를 해석하고 정보에 입각한 결정을 내리는 데 도움을 줄 수 있다.

---

## 한계점과 향후 연구 방향

연구진은 다음과 같은 한계점을 인정한다.

- 일부 이미지에서 객체 검출 정확도가 안전 평가 성능에 영향을 미칠 수 있음
- 모든 이미지가 대한민국 내 현장에서 수집되어 다른 지역으로의 일반화는 검증이 필요함
- 사용된 10가지 위험 상황이 모든 가능한 건설 안전 시나리오를 포함하지 않음
- 이미지 데이터에 대한 의존이 건설 현장의 포괄적인 맥락을 완전히 포착하지 못할 수 있음

향후 연구에서는 다양한 환경 조건에서의 일반화 성능 조사, 더 많은 위험 상황으로의 확장, 건설 현장의 포괄적인 환경을 더 잘 포착하기 위한 영상 및 오디오 같은 추가 데이터 양식의 통합이 필요하다.

---

## 맺음말

건설 현장 안전 모니터링은 단순한 객체 검출 이상을 필요로 한다. 이 연구는 Large Vision-Language Model이 도메인 특화 데이터와 지시로 미세조정될 때 맥락 인식 위험 검출과 해석을 수행할 수 있음을 보여준다.

제안된 프레임워크는 엔드투엔드 건설 안전 평가를 위해 비전-언어 모델링과 도메인 특화 미세조정을 성공적으로 결합한다. 단일 모델 내에서 검출과 추론을 모두 지원함으로써, 이 접근법은 건설 현장 모니터링에서 안전 평가의 해석 가능성과 효과성을 향상시키는 포괄적인 방법을 제공한다.

---

## 글쓴이 소개

<div class="author-card">
    <img src="img/member/student/김태건.jpg" alt="김태건" class="author-photo">
    <div class="author-info">
        <h4>김태건 (Taegeon Kim)</h4>
        <p class="author-affiliation">연세대학교 건설환경공학과 통합과정</p>
        <p class="author-bio">
            건설 현장 CCTV 영상 기반 객체 인식, 도메인 적응, 자동 학습 데이터 생성 등 건설 AI 및 딥러닝 응용을 연구하고 있다. 실제 현장 영상 데이터의 제약과 이를 극복하기 위한 데이터 중심 학습 방법에 관심을 두고 있다.<br><br>
            현재 건설 AI 스타트업 온토(ONTOH)의 CEO로 재직 중이다. 온토는 <strong>Physical AI</strong> 기술 기반 건설 현장 CCTV 영상에서 위험 상황을 인식·해석하는 기술과, 현장 영상과 관리 데이터를 활용해 안전 문서와 보고서를 생성하는 <strong>생성형 AI</strong> 기술을 결합한 AI CCTV 솔루션을 개발하고 있다. 한편, 고령자·기저질환자 등 민감군 근로자를 대상으로 건강 정보를 체계적으로 축적하는 <strong>건강 DB 구축</strong>과 현장 단위의 <strong>보건 모니터링</strong>을 통해, 건설 현장의 선제적 건강·안전 관리를 지원하는 시스템도 함께 개발하고 있다.
        </p>
        <div class="author-contact">
            <a href="mailto:geon9655@gmail.com"><i class="fas fa-envelope"></i> geon9655@gmail.com</a>
            <a href="tel:+82-10-6737-6598"><i class="fas fa-phone"></i> +82-10-6737-6598</a>
            <a href="https://hongjo.github.io/" target="_blank"><i class="fas fa-globe"></i> hongjo.github.io</a>
        </div>
    </div>
</div>
